{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # needed to plot 3-D surfaces\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.00000e+00  1.00000e+00  1.18000e+03 ... -1.22257e+02  1.34000e+03\n",
      "   5.65000e+03]\n",
      " [ 3.00000e+00  2.25000e+00  2.57000e+03 ... -1.22319e+02  1.69000e+03\n",
      "   7.63900e+03]\n",
      " [ 2.00000e+00  1.00000e+00  7.70000e+02 ... -1.22233e+02  2.72000e+03\n",
      "   8.06200e+03]\n",
      " ...\n",
      " [ 2.00000e+00  1.75000e+00  1.80000e+03 ... -1.22060e+02  1.62000e+03\n",
      "   1.12384e+05]\n",
      " [ 4.00000e+00  2.50000e+00  2.40000e+03 ... -1.22339e+02  1.71000e+03\n",
      "   7.90900e+03]\n",
      " [ 4.00000e+00  2.00000e+00  2.37000e+03 ... -1.22279e+02  2.11000e+03\n",
      "   1.93340e+04]]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = np.genfromtxt(os.path.join( 'house_prices_data_training_data.csv'), delimiter=',')\n",
    "\n",
    "X = data[:, 0:17]\n",
    "y = data[:, 17]\n",
    "\n",
    "Xtr = data[1:10801, 0:17]\n",
    "ytr = data[1:10801, 17]\n",
    "\n",
    "Xcv = data[10801:14401, 0:17]\n",
    "ycv = data[10801:14401, 17]\n",
    "\n",
    "Xte = data[14401:18001, 0:17]\n",
    "yte = data[14401:18001, 17]\n",
    "\n",
    "\n",
    "m=y.size\n",
    "\n",
    "m = y.size\n",
    " \n",
    "\n",
    "print(Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize(X):\n",
    "    \n",
    "    # You need to set these values correctly\n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "    \n",
    "\n",
    "    # =========================== YOUR CODE HERE =====================\n",
    "    for i in range (17):\n",
    "        mu = np.mean(X[:,i],axis=0)\n",
    "        sigma = np.std(X[:,i],axis = 0)\n",
    "    X_norm = (X-mu)/sigma\n",
    "    # ================================================================\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize_2(X):\n",
    "    #fuction to add bias feature\n",
    "    \n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(0)\n",
    "    sigma = np.zeros(0)\n",
    "    \n",
    "    for i in range(0,X.shape[1]):\n",
    "        mu=np.concatenate([mu,[np.mean(X[:,i])]], axis=0)\n",
    "        sigma=np.concatenate([sigma,[np.std(X[:,i])]], axis=0)\n",
    "    \n",
    "    X_norm=(X-mu)/sigma\n",
    "    \n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCostMulti(X, y, theta):\n",
    "    \n",
    "    m = y.shape[0]\n",
    "    \n",
    "    J = 0\n",
    "    \n",
    "    H = np.dot(X,theta)\n",
    "    \n",
    "    J = (1/(2*m)) * np.sum(np.square(H-y))\n",
    "    \n",
    "    return J\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
    "    \n",
    "    m = y.shape[0]\n",
    "    \n",
    "    theta = theta.copy()\n",
    "    \n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        theta= theta - (alpha/m)*(np.dot(Xtr,theta.T)-ytr).dot(Xtr)\n",
    "        \n",
    "        J_history.append(computeCostMulti(Xtr, ytr, theta))\n",
    "    \n",
    "    return theta, J_history\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10800,17) and (18,) not aligned: 17 (dim 1) != 18 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3845902c4d72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputeCostMulti\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#cost function pre-gradient descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJ_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradientDescentMulti\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#gradient descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputeCostMulti\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#cost function post-gradient descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-57de7ca9df55>\u001b[0m in \u001b[0;36mgradientDescentMulti\u001b[1;34m(X, y, theta, alpha, num_iters)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mtheta\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mJ_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputeCostMulti\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10800,17) and (18,) not aligned: 17 (dim 1) != 18 (dim 0)"
     ]
    }
   ],
   "source": [
    "alpha = 0.03\n",
    "num_iters = 1000\n",
    "\n",
    "theta = np.zeros(18)\n",
    "\n",
    "X_norm, mu, sigma =featureNormalize(X)\n",
    "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n",
    "\n",
    "print(computeCostMulti(X, y, theta)) #cost function pre-gradient descent\n",
    "\n",
    "theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters) #gradient descent\n",
    "\n",
    "print(computeCostMulti(X, y, theta)) #cost function post-gradient descent\n",
    "\n",
    "\n",
    "#test order of polynomials from 1 to 4\n",
    "\n",
    "#initialize variables for different orders\n",
    "\n",
    "#d=2\n",
    "X_2 = np.concatenate((X, np.square(X)), axis = 1)\n",
    "\n",
    "#d=3\n",
    "X_3 = np.concatenate((X_2, np.power(X,3)), axis = 1)\n",
    "\n",
    "#d=4\n",
    "X_4 = np.concatenate((X_3, np.power(X,4)), axis = 1)\n",
    "\n",
    "#initialize variables for training, validation and testing (different orders)\n",
    "\n",
    "#d=2\n",
    "Xtr_2 = X_2[1:10801, 0:17]\n",
    "Xcv_2 = X_2[10801:14401, 0:17]\n",
    "Xte_2 = X_2[14401:18001, 0:17]\n",
    "\n",
    "#d=3\n",
    "Xtr_3 = X_3[1:10801, 0:17]\n",
    "Xcv_3 = X_3[10801:14401, 0:17]\n",
    "Xte_3 = X_3[14401:18001, 0:17]\n",
    "\n",
    "#d=4\n",
    "Xtr_4 = X_4[1:10801, 0:17]\n",
    "Xcv_4 = X_4[10801:14401, 0:17]\n",
    "Xte_4 = X_4[14401:18001, 0:17]\n",
    "            \n",
    "\n",
    "ytr = data[1:10801, 17]\n",
    "\n",
    "ycv = data[10801:14401, 17]\n",
    "\n",
    "yte = data[14401:18001, 17]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#normalize, cost function and gradient descent of first order \n",
    "\n",
    "Xtr_norm, mu_tr, sigma_tr =featureNormalize_2(Xtr)\n",
    "Xcv_norm, mu_cv, sigma_cv =featureNormalize_2(Xcv)\n",
    "Xte_norm, mu_te, sigma_te =featureNormalize2(Xte)\n",
    "Xtr = np.concatenate([np.ones((10800, 1)), Xtr_norm], axis=1)\n",
    "Xcv = np.concatenate([np.ones((3600, 1)), Xcv_norm], axis=1)\n",
    "Xte = np.concatenate([np.ones((3599, 1)), Xte_norm], axis=1)\n",
    "\n",
    "theta = np.zeros(18)\n",
    "\n",
    "print(computeCostMulti(Xtr, ytr, theta))\n",
    "theta, J_history = gradientDescentMulti(Xtr, ytr, theta, alpha, num_iters)\n",
    "print(computeCostMulti(Xtr, ytr, theta), \"first training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv, ycv, theta),\"first cross validation error\")\n",
    "\n",
    "\n",
    "\n",
    "#normalize, cost function and gradient descent of second order \n",
    "\n",
    "Xtr_2_norm, mu_tr_2, sigma_tr_2 =featureNormalize_2(Xtr_2)\n",
    "Xcv_2_norm, mu_cv_2, sigma_cv_2 =featureNormalize_2(Xcv_2)\n",
    "Xte_2_norm, mu_te_2, sigma_te_2 =featureNormalize_2(Xte_2)\n",
    "Xtr_2 = np.concatenate([np.ones((10800, 1)), Xtr_2_norm], axis=1)\n",
    "Xcv_2 = np.concatenate([np.ones((3600, 1)), Xcv_2_norm], axis=1)\n",
    "Xte_2 = np.concatenate([np.ones((3600, 1)), Xte_2_norm], axis=1)\n",
    "\n",
    "theta_2 = np.zeros(35)\n",
    "\n",
    "print(computeCostMulti(Xtr_2, ytr, theta_2))\n",
    "theta_2, J_history_2 = gradientDescentMulti(Xtr_2, ytr, theta_2, alpha, num_iters)\n",
    "print(computeCostMulti(Xtr_2, ytr, theta_2), \"second training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv_2, ycv, theta_2),\"second cross validation error\")\n",
    "\n",
    "\n",
    "\n",
    "#normalize, cost function and gradient descent of third order \n",
    "\n",
    "Xtr_3_norm, mu_tr_3, sigma_tr_3 =featureNormalize_2(Xtr_3)\n",
    "Xcv_3_norm, mu_cv_3, sigma_cv_3 =featureNormalize_2(Xcv_3)\n",
    "Xte_3_norm, mu_te_3, sigma_te_3 =featureNormalize_2(Xte_3)\n",
    "Xtr_3 = np.concatenate([np.ones((10800, 1)), Xtr_3_norm], axis=1)\n",
    "Xcv_3 = np.concatenate([np.ones((3600, 1)), Xcv_3_norm], axis=1)\n",
    "Xte_3 = np.concatenate([np.ones((3600, 1)), Xte_3_norm], axis=1)\n",
    "\n",
    "theta_3 = np.zeros(52)\n",
    "\n",
    "print(computeCostMulti(Xtr_3, ytr, theta_3))\n",
    "theta_3, J_history_3 = gradientDescentMulti(Xtr_3, ytr, theta_3, alpha, num_iters)\n",
    "print(computeCostMulti(Xtr_3, ytr, theta_3), \"third training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv_3, ycv, theta_3),\"third cross validation error\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#normalize, cost function and gradient descent of third order \n",
    "\n",
    "Xtr_4_norm, mu_tr_4, sigma_tr_4 =featureNormalize_2(Xtr_4)\n",
    "Xcv_4_norm, mu_cv_4, sigma_cv_4 =featureNormalize_2(Xcv_4)\n",
    "Xte_4_norm, mu_te_4, sigma_te_4 =featureNormalize_2(Xte_4)\n",
    "Xtr_4 = np.concatenate([np.ones((10800, 1)), Xtr_4_norm], axis=1)\n",
    "Xcv_4 = np.concatenate([np.ones((3600, 1)), Xcv_4_norm], axis=1)\n",
    "Xte_4 = np.concatenate([np.ones((3600, 1)), Xte_4_norm], axis=1)\n",
    "\n",
    "theta_4 = np.zeros(69)\n",
    "\n",
    "print(computeCostMulti(Xtr_4, ytr, theta_4))\n",
    "theta_4, J_history_4 = gradientDescentMulti(Xtr_4, ytr, theta_4, alpha, num_iters)\n",
    "print(computeCostMulti(Xtr_4, ytr, theta_4), \"third training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv_4, ycv, theta_4),\"third cross validation error\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computinng test errors for the  four degrees\n",
    "\n",
    "\n",
    "#d =1\n",
    "print(computeCostMulti(Xte, yte, theta),\"first testing error\")\n",
    "\n",
    "#d =2\n",
    "print(computeCostMulti(Xte_2, yte, theta_2),\"second testing error\")\n",
    "\n",
    "#d =3\n",
    "print(computeCostMulti(Xte_3, yte, theta_3),\"third testing error\")\n",
    "\n",
    "#d =4\n",
    "print(computeCostMulti(Xte_4, yte, theta_4),\"fourth testing error\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentMultiRegularized(X, y, theta, alpha, num_iters,lambda_):\n",
    "    \n",
    "    #regularization\n",
    "    \n",
    "     m = y.shape[0]\n",
    "        \n",
    "    theta = theta.copy()\n",
    "    \n",
    "    h = np.dot(X,theta)\n",
    "    J_history = []\n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        theta = theta - ((alpha/m)* np.sum(np.dot((h-y),X))) + (np.dot(lambda_, theta))\n",
    "        \n",
    "    J_history.append(computeCostMultiRegularized(X, y, theta,lambda_))\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularization cont_\n",
    "\n",
    "# Load data\n",
    "data = np.genfromtxt(os.path.join( 'house_prices_data_training_data.csv'), delimiter=',')\n",
    "\n",
    "X = data[:, 0:17]\n",
    "y = data[:, 17]\n",
    "\n",
    "Xtr = data[1:10801, 0:17]\n",
    "ytr = data[1:10801, 17]\n",
    "\n",
    "Xcv = data[10801:14401, 0:17]\n",
    "ycv = data[10801:14401, 17]\n",
    "\n",
    "Xte = data[14401:18001, 0:17]\n",
    "yte = data[14401:18001, 17]\n",
    "\n",
    "m = y.size\n",
    "\n",
    "alpha = 0.03\n",
    "\n",
    "num_iters = 1000\n",
    "\n",
    "\n",
    "#test order of polynomials from 1 to 4\n",
    "\n",
    "#initialize variables for different orders\n",
    "\n",
    "#d=2\n",
    "X_2 = np.concatenate((X, np.square(X)), axis = 1)\n",
    "\n",
    "#d=3\n",
    "X_3 = np.concatenate((X_2, np.power(X,3)), axis = 1)\n",
    "\n",
    "#d=4\n",
    "X_4 = np.concatenate((X_3, np.power(X,4)), axis = 1)\n",
    "\n",
    "#initialize variables for training, validation and testing (different orders)\n",
    "\n",
    "#d=2\n",
    "Xtr_2 = X_2[1:10801, 0:17]\n",
    "Xcv_2 = X_2[10801:14401, 0:17]\n",
    "Xte_2 = X_2[14401:18000, 0:17]\n",
    "\n",
    "#d=3\n",
    "Xtr_3 = X_3[1:10801, 0:17]\n",
    "Xcv_3 = X_3[10801:14401, 0:17]\n",
    "Xte_3 = X_3[14401:18000, 0:17]\n",
    "\n",
    "#d=4\n",
    "Xtr_4 = X_4[1:10801, 0:17]\n",
    "Xcv_4 = X_4[10801:14401, 0:17]\n",
    "Xte_4 = X_4[14401:18000, 0:17]\n",
    "\n",
    "\n",
    "\n",
    "#normalize first order\n",
    "\n",
    "X_norm, mu, sigma =featureNormalize(X)\n",
    "\n",
    "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n",
    "\n",
    "Xtr=X[1:10800,0:17]\n",
    "Xcv=X[10801:14400,0:17]\n",
    "Xte=X[14401:18000,0:17]\n",
    "\n",
    "\n",
    "theta = np.zeros(18)\n",
    "lambda_=0.1\n",
    "print(computeCostMultiRegularized(Xtr, ytr, theta,lambda_))\n",
    "theta, J_history = gradientDescentMultiRegularized(Xtr, ytr, theta, alpha, num_iters,lambda_)\n",
    "print(computeCostMultiRegularized(Xtr, ytr, theta,lambda_),\"first regularized training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv, ycv, theta),\"first rregularized cross validationn error\")\n",
    "\n",
    "\n",
    "#normalize second order\n",
    "\n",
    "Xtr_2_norm, mu_tr_2, sigma_tr_2 =featureNormalize_2(Xtr_2)\n",
    "Xcv_2_norm, mu_cv_2, sigma_cv_2 =featureNormalize_2(Xcv_2)\n",
    "Xte_2_norm, mu_te_2, sigma_te_2 =featureNormalize_2(Xte_2)\n",
    "Xtr_2 = np.concatenate([np.ones((10800, 1)), Xtr_2_norm], axis=1)\n",
    "Xcv_2 = np.concatenate([np.ones((3600, 1)), Xcv_2_norm], axis=1)\n",
    "Xte_2 = np.concatenate([np.ones((3600, 1)), Xte_2_norm], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "theta = np.zeros(35)\n",
    "lambda_=0.1\n",
    "print(computeCostMultiRegularized(Xtr_2, ytr, theta_2,lambda_))\n",
    "theta_2, J_history_2 = gradientDescentMultiRegularized(Xt_2, ytr, theta_2, alpha, num_iters,lambda_)\n",
    "print(computeCostMultiRegularized(Xtr_2, ytr, theta_2,lambda_),\"second regularized training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv_2, ycv, theta_2),\"second regularized cross validationn error\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#normalize third order\n",
    "\n",
    "Xtr_3_norm, mu_tr_3, sigma_tr_3 =featureNormalize_2(Xtr_3)\n",
    "Xcv_3_norm, mu_cv_3, sigma_cv_3 =featureNormalize_2(Xcv_3)\n",
    "Xte_3_norm, mu_te_3, sigma_te_3 =featureNormalize_2(Xte_3)\n",
    "Xtr_3 = np.concatenate([np.ones((10800, 1)), Xtr_3_norm], axis=1)\n",
    "Xcv_3 = np.concatenate([np.ones((3600, 1)), Xcv_3_norm], axis=1)\n",
    "Xte_3 = np.concatenate([np.ones((3600, 1)), Xte_3_norm], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "theta = np.zeros(52)\n",
    "lambda_=0.1\n",
    "print(computeCostMultiRegularized(Xtr_3, ytr, theta_3,lambda_))\n",
    "theta_3, J_history_3 = gradientDescentMultiRegularized(Xt_3, ytr, theta_3, alpha, num_iters,lambda_)\n",
    "print(computeCostMultiRegularized(Xtr_3, ytr, theta_3,lambda_),\"second regularized training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv_3, ycv, theta_3),\"third regularized cross validationn error\")\n",
    "\n",
    "\n",
    "\n",
    "#normalize third order\n",
    "\n",
    "Xtr_4_norm, mu_tr_4, sigma_tr_4 =featureNormalize_2(Xtr_4)\n",
    "Xcv_4_norm, mu_cv_4, sigma_cv_4 =featureNormalize_2(Xcv_4)\n",
    "Xte_4_norm, mu_te_4, sigma_te_4 =featureNormalize_2(Xte_4)\n",
    "Xtr_4 = np.concatenate([np.ones((10800, 1)), Xtr_4_norm], axis=1)\n",
    "Xcv_4 = np.concatenate([np.ones((3600, 1)), Xcv_4_norm], axis=1)\n",
    "Xte_4 = np.concatenate([np.ones((3600, 1)), Xte_4_norm], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "theta = np.zeros(69)\n",
    "lambda_=0.1\n",
    "print(computeCostMultiRegularized(Xtr_4, ytr, theta_4,lambda_))\n",
    "theta_4, J_history_4 = gradientDescentMultiRegularized(Xt_4, ytr, theta_4, alpha, num_iters,lambda_)\n",
    "print(computeCostMultiRegularized(Xtr_4, ytr, theta_4,lambda_),\"second regularized training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv_4, ycv, theta_4),\"third regularized cross validationn error\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularization testing error for four degrees\n",
    "\n",
    "#d=1\n",
    "print(computeCostMultiRegularized(Xte, yte, theta,lambda_),\"first regularized testing error\")\n",
    "\n",
    "#d=2\n",
    "print(computeCostMultiRegularized(Xte_2, yte, theta_2,lambda_),\"second regularized testing error\")\n",
    "\n",
    "#d=3\n",
    "print(computeCostMultiRegularized(Xte_3, yte, theta_3,lambda_),\"third regularized testing error\")\n",
    "\n",
    "#d=4\n",
    "print(computeCostMultiRegularized(Xte_4, yte, theta_4,lambda_),\"fourth regularized testing error\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
