{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # needed to plot 3-D surfaces\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.genfromtxt(os.path.join( 'house_prices_data_training_data.csv'), delimiter=',')\n",
    "\n",
    "X = data[:, 0:17]\n",
    "y = data[:, 17]\n",
    "\n",
    "Xtr = data[1:10801, 0:17]\n",
    "ytr = data[1:10801, 17]\n",
    "\n",
    "Xcv = data[10801:14401, 0:17]\n",
    "ycv = data[10801:14401, 17]\n",
    "\n",
    "Xte = data[14401:18001, 0:17]\n",
    "yte = data[14401:18001, 17]\n",
    "\n",
    "\n",
    "m=y.size\n",
    "\n",
    "m = y.size\n",
    " \n",
    "\n",
    "print(Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize(X):\n",
    "    \n",
    "    # You need to set these values correctly\n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "    \n",
    "\n",
    "    # =========================== YOUR CODE HERE =====================\n",
    "    for i in range (17):\n",
    "        mu = np.mean(X[:,i],axis=0)\n",
    "        sigma = np.std(X[:,i],axis = 0)\n",
    "    X_norm = (X-mu)/sigma\n",
    "    # ================================================================\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize_2(X):\n",
    "    #fuction to add bias feature\n",
    "    \n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(0)\n",
    "    sigma = np.zeros(0)\n",
    "    \n",
    "    for i in range(0,X.shape[1]):\n",
    "        mu=np.concatenate([mu,[np.mean(X[:,i])]], axis=0)\n",
    "        sigma=np.concatenate([sigma,[np.std(X[:,i])]], axis=0)\n",
    "    \n",
    "    X_norm=(X-mu)/sigma\n",
    "    \n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCostMulti(X, y, theta):\n",
    "    \n",
    "    m = y.shape[0]\n",
    "    \n",
    "    J = 0\n",
    "    \n",
    "    H = np.dot(X,theta)\n",
    "    \n",
    "    J = (1/(2*m)) * np.sum(np.square(H-y))\n",
    "    \n",
    "    return J\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
    "    \n",
    "    m = y.shape[0]\n",
    "    \n",
    "    theta = theta.copy()\n",
    "    \n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        theta= theta - (alpha/m)*(np.dot(Xtr,theta.T)-ytr).dot(Xtr)\n",
    "        \n",
    "        J_history.append(computeCostMulti(Xtr, ytr, theta))\n",
    "    \n",
    "    return theta, J_history\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.03\n",
    "num_iters = 1000\n",
    "\n",
    "theta = np.zeros(18)\n",
    "\n",
    "X_norm, mu, sigma =featureNormalize(X)\n",
    "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n",
    "\n",
    "print(computeCostMulti(X, y, theta)) #cost function pre-gradient descent\n",
    "\n",
    "theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters) #gradient descent\n",
    "\n",
    "print(computeCostMulti(X, y, theta)) #cost function post-gradient descent\n",
    "\n",
    "\n",
    "#test order of polynomials from 1 to 4\n",
    "\n",
    "#initialize variables for different orders\n",
    "\n",
    "#d=2\n",
    "X_2 = np.concatenate((X, np.square(X)), axis = 1)\n",
    "\n",
    "#d=3\n",
    "X_3 = np.concatenate((X_2, np.power(X,3)), axis = 1)\n",
    "\n",
    "#d=4\n",
    "X_4 = np.concatenate((X_3, np.power(X,4)), axis = 1)\n",
    "\n",
    "#initialize variables for training, validation and testing (different orders)\n",
    "\n",
    "#d=2\n",
    "Xtr_2 = X_2[1:10801, 0:17]\n",
    "Xcv_2 = X_2[10801:14401, 0:17]\n",
    "Xte_2 = X_2[14401:18001, 0:17]\n",
    "\n",
    "#d=3\n",
    "Xtr_3 = X_3[1:10801, 0:17]\n",
    "Xcv_3 = X_3[10801:14401, 0:17]\n",
    "Xte_3 = X_3[14401:18001, 0:17]\n",
    "\n",
    "#d=4\n",
    "Xtr_4 = X_4[1:10801, 0:17]\n",
    "Xcv_4 = X_4[10801:14401, 0:17]\n",
    "Xte_4 = X_4[14401:18001, 0:17]\n",
    "            \n",
    "\n",
    "ytr = data[1:10801, 17]\n",
    "\n",
    "ycv = data[10801:14401, 17]\n",
    "\n",
    "yte = data[14401:18001, 17]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#normalize, cost function and gradient descent of first order \n",
    "\n",
    "Xtr_norm, mu_tr, sigma_tr =featureNormalize_2(Xtr)\n",
    "Xcv_norm, mu_cv, sigma_cv =featureNormalize_2(Xcv)\n",
    "Xte_norm, mu_te, sigma_te =featureNormalize2(Xte)\n",
    "Xtr = np.concatenate([np.ones((10800, 1)), Xtr_norm], axis=1)\n",
    "Xcv = np.concatenate([np.ones((3600, 1)), Xcv_norm], axis=1)\n",
    "Xte = np.concatenate([np.ones((3599, 1)), Xte_norm], axis=1)\n",
    "\n",
    "theta = np.zeros(18)\n",
    "\n",
    "print(computeCostMulti(Xtr, ytr, theta))\n",
    "theta, J_history = gradientDescentMulti(Xtr, ytr, theta, alpha, num_iters)\n",
    "print(computeCostMulti(Xtr, ytr, theta), \"first training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv, ycv, theta),\"first cross validation error\")\n",
    "\n",
    "\n",
    "\n",
    "#normalize, cost function and gradient descent of second order \n",
    "\n",
    "Xtr_2_norm, mu_tr_2, sigma_tr_2 =featureNormalize_2(Xtr_2)\n",
    "Xcv_2_norm, mu_cv_2, sigma_cv_2 =featureNormalize_2(Xcv_2)\n",
    "Xte_2_norm, mu_te_2, sigma_te_2 =featureNormalize_2(Xte_2)\n",
    "Xtr_2 = np.concatenate([np.ones((10800, 1)), Xtr_2_norm], axis=1)\n",
    "Xcv_2 = np.concatenate([np.ones((3600, 1)), Xcv_2_norm], axis=1)\n",
    "Xte_2 = np.concatenate([np.ones((3600, 1)), Xte_2_norm], axis=1)\n",
    "\n",
    "theta_2 = np.zeros(35)\n",
    "\n",
    "print(computeCostMulti(Xtr_2, ytr, theta_2))\n",
    "theta_2, J_history_2 = gradientDescentMulti(Xtr_2, ytr, theta_2, alpha, num_iters)\n",
    "print(computeCostMulti(Xtr_2, ytr, theta_2), \"second training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv_2, ycv, theta_2),\"second cross validation error\")\n",
    "\n",
    "\n",
    "\n",
    "#normalize, cost function and gradient descent of third order \n",
    "\n",
    "Xtr_3_norm, mu_tr_3, sigma_tr_3 =featureNormalize_2(Xtr_3)\n",
    "Xcv_3_norm, mu_cv_3, sigma_cv_3 =featureNormalize_2(Xcv_3)\n",
    "Xte_3_norm, mu_te_3, sigma_te_3 =featureNormalize_2(Xte_3)\n",
    "Xtr_3 = np.concatenate([np.ones((10800, 1)), Xtr_3_norm], axis=1)\n",
    "Xcv_3 = np.concatenate([np.ones((3600, 1)), Xcv_3_norm], axis=1)\n",
    "Xte_3 = np.concatenate([np.ones((3600, 1)), Xte_3_norm], axis=1)\n",
    "\n",
    "theta_3 = np.zeros(52)\n",
    "\n",
    "print(computeCostMulti(Xtr_3, ytr, theta_3))\n",
    "theta_3, J_history_3 = gradientDescentMulti(Xtr_3, ytr, theta_3, alpha, num_iters)\n",
    "print(computeCostMulti(Xtr_3, ytr, theta_3), \"third training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv_3, ycv, theta_3),\"third cross validation error\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#normalize, cost function and gradient descent of third order \n",
    "\n",
    "Xtr_4_norm, mu_tr_4, sigma_tr_4 =featureNormalize_2(Xtr_4)\n",
    "Xcv_4_norm, mu_cv_4, sigma_cv_4 =featureNormalize_2(Xcv_4)\n",
    "Xte_4_norm, mu_te_4, sigma_te_4 =featureNormalize_2(Xte_4)\n",
    "Xtr_4 = np.concatenate([np.ones((10800, 1)), Xtr_4_norm], axis=1)\n",
    "Xcv_4 = np.concatenate([np.ones((3600, 1)), Xcv_4_norm], axis=1)\n",
    "Xte_4 = np.concatenate([np.ones((3600, 1)), Xte_4_norm], axis=1)\n",
    "\n",
    "theta_4 = np.zeros(69)\n",
    "\n",
    "print(computeCostMulti(Xtr_4, ytr, theta_4))\n",
    "theta_4, J_history_4 = gradientDescentMulti(Xtr_4, ytr, theta_4, alpha, num_iters)\n",
    "print(computeCostMulti(Xtr_4, ytr, theta_4), \"third training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv_4, ycv, theta_4),\"third cross validation error\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computinng test errors for the  four degrees\n",
    "\n",
    "\n",
    "#d =1\n",
    "print(computeCostMulti(Xte, yte, theta),\"first testing error\")\n",
    "\n",
    "#d =2\n",
    "print(computeCostMulti(Xte_2, yte, theta_2),\"second testing error\")\n",
    "\n",
    "#d =3\n",
    "print(computeCostMulti(Xte_3, yte, theta_3),\"third testing error\")\n",
    "\n",
    "#d =4\n",
    "print(computeCostMulti(Xte_4, yte, theta_4),\"fourth testing error\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentMultiRegularized(X, y, theta, alpha, num_iters,lambda_):\n",
    "    \n",
    "    #regularization\n",
    "    \n",
    "     m = y.shape[0]\n",
    "        \n",
    "    theta = theta.copy()\n",
    "    \n",
    "    h = np.dot(X,theta)\n",
    "    J_history = []\n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        theta = theta - ((alpha/m)* np.sum(np.dot((h-y),X))) + (np.dot(lambda_, theta))\n",
    "        \n",
    "    J_history.append(computeCostMultiRegularized(X, y, theta,lambda_))\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularization cont_\n",
    "\n",
    "# Load data\n",
    "data = np.genfromtxt(os.path.join( 'house_prices_data_training_data.csv'), delimiter=',')\n",
    "\n",
    "X = data[:, 0:17]\n",
    "y = data[:, 17]\n",
    "\n",
    "Xtr = data[1:10801, 0:17]\n",
    "ytr = data[1:10801, 17]\n",
    "\n",
    "Xcv = data[10801:14401, 0:17]\n",
    "ycv = data[10801:14401, 17]\n",
    "\n",
    "Xte = data[14401:18001, 0:17]\n",
    "yte = data[14401:18001, 17]\n",
    "\n",
    "m = y.size\n",
    "\n",
    "alpha = 0.03\n",
    "\n",
    "num_iters = 1000\n",
    "\n",
    "\n",
    "#test order of polynomials from 1 to 4\n",
    "\n",
    "#initialize variables for different orders\n",
    "\n",
    "#d=2\n",
    "X_2 = np.concatenate((X, np.square(X)), axis = 1)\n",
    "\n",
    "#d=3\n",
    "X_3 = np.concatenate((X_2, np.power(X,3)), axis = 1)\n",
    "\n",
    "#d=4\n",
    "X_4 = np.concatenate((X_3, np.power(X,4)), axis = 1)\n",
    "\n",
    "#initialize variables for training, validation and testing (different orders)\n",
    "\n",
    "#d=2\n",
    "Xtr_2 = X_2[1:10801, 0:17]\n",
    "Xcv_2 = X_2[10801:14401, 0:17]\n",
    "Xte_2 = X_2[14401:18000, 0:17]\n",
    "\n",
    "#d=3\n",
    "Xtr_3 = X_3[1:10801, 0:17]\n",
    "Xcv_3 = X_3[10801:14401, 0:17]\n",
    "Xte_3 = X_3[14401:18000, 0:17]\n",
    "\n",
    "#d=4\n",
    "Xtr_4 = X_4[1:10801, 0:17]\n",
    "Xcv_4 = X_4[10801:14401, 0:17]\n",
    "Xte_4 = X_4[14401:18000, 0:17]\n",
    "\n",
    "\n",
    "\n",
    "#normalize first order\n",
    "\n",
    "X_norm, mu, sigma =featureNormalize(X)\n",
    "\n",
    "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n",
    "\n",
    "Xtr=X[1:10800,0:17]\n",
    "Xcv=X[10801:14400,0:17]\n",
    "Xte=X[14401:18000,0:17]\n",
    "\n",
    "\n",
    "theta = np.zeros(18)\n",
    "lambda_=0.1\n",
    "print(computeCostMultiRegularized(Xtr, ytr, theta,lambda_))\n",
    "theta, J_history = gradientDescentMultiRegularized(Xtr, ytr, theta, alpha, num_iters,lambda_)\n",
    "print(computeCostMultiRegularized(Xtr, ytr, theta,lambda_),\"first regularized training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv, ycv, theta),\"first rregularized cross validationn error\")\n",
    "\n",
    "\n",
    "#normalize second order\n",
    "\n",
    "Xtr_2_norm, mu_tr_2, sigma_tr_2 =featureNormalize_2(Xtr_2)\n",
    "Xcv_2_norm, mu_cv_2, sigma_cv_2 =featureNormalize_2(Xcv_2)\n",
    "Xte_2_norm, mu_te_2, sigma_te_2 =featureNormalize_2(Xte_2)\n",
    "Xtr_2 = np.concatenate([np.ones((10800, 1)), Xtr_2_norm], axis=1)\n",
    "Xcv_2 = np.concatenate([np.ones((3600, 1)), Xcv_2_norm], axis=1)\n",
    "Xte_2 = np.concatenate([np.ones((3600, 1)), Xte_2_norm], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "theta = np.zeros(35)\n",
    "lambda_=0.1\n",
    "print(computeCostMultiRegularized(Xtr_2, ytr, theta_2,lambda_))\n",
    "theta_2, J_history_2 = gradientDescentMultiRegularized(Xt_2, ytr, theta_2, alpha, num_iters,lambda_)\n",
    "print(computeCostMultiRegularized(Xtr_2, ytr, theta_2,lambda_),\"second regularized training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv_2, ycv, theta_2),\"second regularized cross validationn error\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#normalize third order\n",
    "\n",
    "Xtr_3_norm, mu_tr_3, sigma_tr_3 =featureNormalize_2(Xtr_3)\n",
    "Xcv_3_norm, mu_cv_3, sigma_cv_3 =featureNormalize_2(Xcv_3)\n",
    "Xte_3_norm, mu_te_3, sigma_te_3 =featureNormalize_2(Xte_3)\n",
    "Xtr_3 = np.concatenate([np.ones((10800, 1)), Xtr_3_norm], axis=1)\n",
    "Xcv_3 = np.concatenate([np.ones((3600, 1)), Xcv_3_norm], axis=1)\n",
    "Xte_3 = np.concatenate([np.ones((3600, 1)), Xte_3_norm], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "theta = np.zeros(52)\n",
    "lambda_=0.1\n",
    "print(computeCostMultiRegularized(Xtr_3, ytr, theta_3,lambda_))\n",
    "theta_3, J_history_3 = gradientDescentMultiRegularized(Xt_3, ytr, theta_3, alpha, num_iters,lambda_)\n",
    "print(computeCostMultiRegularized(Xtr_3, ytr, theta_3,lambda_),\"second regularized training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv_3, ycv, theta_3),\"third regularized cross validationn error\")\n",
    "\n",
    "\n",
    "\n",
    "#normalize third order\n",
    "\n",
    "Xtr_4_norm, mu_tr_4, sigma_tr_4 =featureNormalize_2(Xtr_4)\n",
    "Xcv_4_norm, mu_cv_4, sigma_cv_4 =featureNormalize_2(Xcv_4)\n",
    "Xte_4_norm, mu_te_4, sigma_te_4 =featureNormalize_2(Xte_4)\n",
    "Xtr_4 = np.concatenate([np.ones((10800, 1)), Xtr_4_norm], axis=1)\n",
    "Xcv_4 = np.concatenate([np.ones((3600, 1)), Xcv_4_norm], axis=1)\n",
    "Xte_4 = np.concatenate([np.ones((3600, 1)), Xte_4_norm], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "theta = np.zeros(69)\n",
    "lambda_=0.1\n",
    "print(computeCostMultiRegularized(Xtr_4, ytr, theta_4,lambda_))\n",
    "theta_4, J_history_4 = gradientDescentMultiRegularized(Xt_4, ytr, theta_4, alpha, num_iters,lambda_)\n",
    "print(computeCostMultiRegularized(Xtr_4, ytr, theta_4,lambda_),\"second regularized training error\")\n",
    "\n",
    "print(computeCostMulti(Xcv_4, ycv, theta_4),\"third regularized cross validationn error\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularization testing error for four degrees\n",
    "\n",
    "#d=1\n",
    "print(computeCostMultiRegularized(Xte, yte, theta,lambda_),\"first regularized testing error\")\n",
    "\n",
    "#d=2\n",
    "print(computeCostMultiRegularized(Xte_2, yte, theta_2,lambda_),\"second regularized testing error\")\n",
    "\n",
    "#d=3\n",
    "print(computeCostMultiRegularized(Xte_3, yte, theta_3,lambda_),\"third regularized testing error\")\n",
    "\n",
    "#d=4\n",
    "print(computeCostMultiRegularized(Xte_4, yte, theta_4,lambda_),\"fourth regularized testing error\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
